---
title: "NATIONALISTIC BIAS IN SPORT PERFORMANCE EVALUATIONS"
subtitle: "An example from the ski jumping World Cup"
runhead: Judging biases in skijumping
author:
- affiliation: Department of Sociology and Human Geography, University of Oslo.
  name: Torkild Hovde Lyngstad
- affiliation: European University Institute
  name: Juho Härkönen
- affiliation: Department of Medical Statistics, University of Oslo
  name: Leiv Tore Salte Rønneberg
date: "14 september 2017"
keywords: nationalistic bias, skijumping, judges, fixed effects
abstract: "Illegitimate biases of non-independent judges represent a threat to the legitimacy of international sport competitions. Judges’ nationalities represent one source of bias, as they consciously or subconsciously may prefer athletes from their own nation. Such biases may affect the outcomes of competitions. The literature offers no complete consensus on the magnitude, origin and stability of such biases. In this paper, we shed light on these problems, using international ski jumping as an example. We draw on data from the FIS World Cup competitions in the 2006-2008 and 2015-2016 seasons and estimate a series of fixed-effects models to test hypotheses on nationalistic biases. Our results reaffirm suspicions of nationalistic bias in major ski jumping competitions, but also show their magnitude is too little to be of major relevance to competition outcomes. The biases vary between nations, but do not change markedly over the study period."
thanks: "The authors are grateful for financial support from the Småforsk programme at the University of Oslo, and to Marte Knutsson for research assistance in the early phase of establishing the data set.  At publication time, all code and material used to produce this paper (with the exception of the proprietary data) will be available. The authors are also grateful to Matti Nykänen for being an enduring source of inspiration in many aspects of our lives."
output:
  word_document:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
    template: /home/torkildl/Dropbox/Setups/thl/rmd-xelatex-template-ms.tex
  html_document: default
bibliography: /home/torkildl/Dropbox/Literature/thl-main-library.bib
anonymous: no
fontsize: 12pt
geometry: margin=2cm
header-includes:
    - \usepackage{placeins}
    - \usepackage{dcolumn}
    - \usepackage{tabularx}
    - \usepackage{lscape}
    - \usepackage{caption}
fig_caption: false
fig.align: "center"
fig.width: 5
---

```{r analysis, error=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#
# Analysis code for skijumping analysis
#
library(haven)
library(stringr)
library(lfe)
library(stargazer)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
library(ggrepel)
library(here)
library(broom)
library(purrr)
library(pander)

### SEASON 2005-06 DATA FROM EARLY ANALYSIS
# Read in data
jumps <- as.data.frame(read_dta(here("data_prepared.dta"))) %>%
    select(order(names(.))) %>%
    arrange(jumpid)
tbl_df(jumps)

namevars <- str_c("judge_name",as.character(seq(1:5)))
nationvars <- str_c("judge_nation",as.character(seq(1:5)))
ptvars <- str_c("judge",as.character(seq(1:5)))
gathervars <- c(namevars,nationvars,ptvars)

j <- jumps %>%
    select(jumpid,starts_with("judge"),-judgetotal) %>%
    gather(key="key", value="jinfo", judge_name1:judge_name5, judge_nation1:judge_nation5,judge1:judge5) %>%
    mutate(judgeno = as.numeric(str_sub(key,start = -1))) %>%
    mutate(jvar = str_sub(key,end = -2)) %>%
    select(-key) %>%
    spread(key = jvar, value = jinfo) %>%
    arrange(jumpid) %>%
    left_join(.,jumps,by ="jumpid") %>%
    .[, !names(.) %in% gathervars]
tbl_df(j)

### Correct judge name spellings
pairs <- matrix(c("YERLY James","YERRLY James","ASPHAUG Kolbjoern","ASPHAUG Kolbjoer","DALLE AVE Sandro","DALLE Ave Sandro","EGLOFF Ernst","EGLOFF Emst","KARJALAINEN Pirjo","KARJALAINEN Pirvo","KUUSINEN Eero","KUUSINE Eero","LOENG Geir","LOENG Geir S.","LORENZ Michael","LORENTZ Michael","NYMAN Tom","NYMAN Torn","SCHMIEDER Jorg","SCHMIEDER Joerg","SCHMIEDERER Konrad","SCHIMIEDERER Konrad"), ncol=2, byrow=TRUE)
pairs[1,1]
for (x in 1:nrow(pairs)) {
    pair <- pairs[x,]
    j <- j %>% mutate(judge_name = ifelse(judge_name==pair[2],pair[1],judge_name))
}

### Various data preparation
d <- j %>% 
  # Correct erroneous nation coding
  mutate(judge_nation = ifelse(judge_nation=="JAP", "JPN", judge_nation)) %>%
  # Convert to factors
  mutate(judge_name = as.factor(judge_name)) %>%
  mutate(judge_nation = as.factor(judge_nation)) %>%
  mutate(country = as.factor(country)) %>%
  # Generate indicator of national bias
  mutate(natbias = ifelse(competitornation==judge_nation,1,0)) %>%
  # Generate indicator of own nation represented in judge panel 
  group_by(jumpid) %>%
  mutate(represented = max(natbias)) %>%
  ungroup %>%
  # and indicator of compansation bias by other judges
  mutate(compensating = represented - natbias) %>%
  # Generate home field advantage dummy
  mutate(athome = ifelse(competitornation==country,1,0)) %>%
  # Generate indicator of national biar per country
  mutate(countrybias = ifelse(natbias==1,as.character(judge_nation),"NON")) %>%
  mutate(countrybias = as.factor(countrybias)) %>%
  # Home field advantage variables
  mutate(athome = ifelse(competitornation==country,1,0)) %>%
  mutate(competitorname = tolower(competitorname)) %>%
  mutate(athseason = as.factor(str_c(competitorname,as.character(season)))) %>%
  mutate(judge = as.numeric(judge)) %>% 
  # Drop unneeded variables
  select(everything())


#
# Season 2015-2016 analysis
#
season2016 <- data.table::fread(here("scrape/scraped-data-season-2016.csv"), stringsAsFactors = F)
scores16 <- season2016 %>% 
    select(contains("judge"), competitornation = competitorNation, country, place, speed, length, competitorname = competitorName, gender) %>%
    mutate(jumpid = row_number()) %>%
    gather(key=jud, value=val, contains("judge")) %>%
    mutate(info = case_when(str_detect(jud, "Name") ~ "judge_name",
                            str_detect(jud,"Nation") ~ "judge_nation",
                            TRUE ~ "judge")) %>%
    mutate(ltr = str_sub(jud, start=-1)) %>%
    select(-jud) %>%
    group_by(jumpid, ltr) %>%
    arrange(jumpid, ltr) %>% 
    spread(key=info, value=val) %>% 
    ungroup %>% 
    mutate(natbias = if_else(competitornation==judge_nation,1,0)) %>%
    mutate_at(c("judge"), as.numeric) %>% 
    mutate(countrybias = factor(ifelse(natbias==1,as.character(judge_nation),"NON"))) %>% 
    mutate(competitionplace = str_sub(place, start=1,end=-7)) %>% 
    mutate(athome = if_else(country==competitornation,1,0)) %>% 
    mutate(competitorname = tolower(competitorname))


### Combine seasons
###
###
scores06 <- setNames(d, tolower(names(d))) 
scores16 <- setNames(scores16, tolower(names(scores16)))

all_scores <- bind_rows(scores06,scores16, .id="whichseason") %>% 
    select(whichseason, jumpid, judge, judge_name, judge_nation, natbias, countrybias, competitionplace, competitorname) %>% 
    mutate(theseason = if_else(whichseason==1, "2005-06","2015-16")) %>% 
    mutate(seasondummy = if_else(whichseason==1,0,1))



# ESTIMATIONS: NATIONAL BIAS MODELS
#
# Model 1, Naïve model of national bias
model1 <- lm(data = all_scores,judge ~ natbias)
summary(model1)

# Model 2: introducing jump fixed effects
model2 <- felm(data = all_scores, judge ~ natbias | jumpid)
summary(model2)

# Model 2 with judge fixed effects for looking at leniency
model2b <- felm(data = all_scores, judge ~ natbias | jumpid + judge_name)
summary(model2b)

# Model 3: Does national bias vary among nations?
all_scores$countrybias_ord <- relevel(as.factor(all_scores$countrybias), ref="NON")
model3 <- felm(data = all_scores, judge ~ relevel(countrybias_ord,ref = "NON") | jumpid)
summary(model3)


# Model 4: Estimating changes over time in national bias
model4 <- felm(data = all_scores, judge ~ natbias + natbias*seasondummy + seasondummy| jumpid)
summary(model4)
bias_main <- tidy(model4) %>% filter(term=="natbias") %>% pull(estimate)
bias_interact <- tidy(model4) %>% filter(term=="natbias:seasondummy") %>% pull(estimate)

```

# INTRODUCTION

Many sports use qualified experts to rank and evaluate performances. For example, ski jumping competitions have a panel of five judges who independently evaluate each performance. Similar systems are used in diving, figure skating, and numerous other sports. The experts may completely or partially decide the outcome of competitions. 

A prerogative of the system is that experts judge performances in an unbiased and neutral manner. However, there is a large potential for biases in such judgements [@meyer_selecting_1991]. Experts may, for example, overestimate performances by competitors from their own country, overvalue certain stylistic elements, or unconsciously adjust evaluations in response to spectator expectations. Such biases may then be consequential in determining the outcome of competitions. Expert judgements are used well beyond the sports domain, and the relevance of studying expert judgements may inform several important societal domains. Expert judgements are widely used, for example, when evaluating applicants to universities, evaluating research grant proposals (Marsh et al. 2008), and in assessing job applicants (cf. @fasang_recruitment_2006; @bursell_name_2012). Understanding the extent of and processes underlying such biases is important for any attempts to remove their effects.

In the present paper, we set out to study two possible types of bias in evaluations of ski jumping performances: nationalistic bias and home-field advantage bias. Nationalistic bias refers to biases in which the judges (positively) evaluate contenders from their own country, whereas home-field advantage bias arises if judges favour contenders from the country in which the contest is held. To answer our questions, we use data from two periods, the 2006-2008 seasons and the 2015-2016 season, of the Federation International de Ski (FIS) World Cup series of ski jumping contests.

We contribute to the literature on nationalistic biases in several ways. First, we assess to what extent nationalistic bias can be explained by unobserved characteristics of the performance. Second, we consider national variations in such bias, and discuss this variation in light of sociological theory of evaluation and valuation. Third, by using our data from two time periods and comparing our results to those obtained with similar data but from the markedly different context of the Olympic games, a highest-stakes-contest [@zitzewitz_nationalism_2006], we can shed light on the role of different institutional and incentive contexts and changes over time in the magnitude of bias.


# THEORY AND RELEVANT LITERATURE

There is an extant scholarly literature that explores the existence and magnitude of subjective biases in sports evaluations. These biases may affect results or other outcomes in favor of what is in principle irrelevant aspects of competitors or other actors in the sport. Research have documented biases that promotes profits for the league owner or organization, racial and ethnic biases, nationalistic biases, as well as home advantage biases. 

Research on biases in basketball illustrates the breadth of the field. In their study of American professional basketball, Price, Remer and Stone [-@price_subperfect_2012] found that the referees were biased towards calls that would increase profits for the league. More specifically, in turnovers, the referees tend to favour the home team, the losing team in a particular game, and the losing teams of the play-off series. In turn these biases can lead to increased ticket sales and ad-revenue due to more exciting, closer games; and ultimately even extend the playoff series itself, garnering more revenue. Even though these biases may operate towards profit-maximizing goals, the authors note that they need not result from any conscious behaviour on behalf of the referees. 

Two related papers explore a potential racial bias among NBA referees, and its consequences for betting markets [@price_racial_2010; @larsen_racial_2008]. The authors note that there is a significant difference between fouls called when the athlete and referees are of the same race versus when they are not. The difference is large enough to be an important factor in determining game outcomes, making it a viable tactic to pursue in betting markets. Analysing data from two seasons, they find that when the majority of judges are white, betting on the team that has more minutes (expected) played by white players will beat the point spread over 50% of the time.


Nationalistic bias, where judges favour athletes from their home country (or otherwise similar ones in terms of national culture)  in a systematic way would be most evident in certain nationalistic competitions such as world cups or Olympics. Evidence of these kinds of biases have been found in many different sports, including rugby [@page_evidence_2010] , muay thai [@myers_evidence_2006], figure skating [@yang_cultural_2006], gymnastics [@callahan_cultural_2016], and surfing [@sampaio_three_2012].

In their study of the 2000 Olympic diving competition, Emerson, Seltzer and Lin [@emerson_assessing_2009] found evidence of strong biases in some of the judges; both nationalistic ones, and against competitors from certain other nations. Based on their model, they re-estimated the results, removing the biases to obtain the objective quality of the dive, and isolated a case where the medals might have changed hands – had the judges been completely unbiased. Zitzewitz [-@zitzewitz_nationalism_2006] made a similar analysis of datasets from the 2002 Salt Lake City Winter Olympics and found evidence of nationalistic biases in both ski jumping and figure skating. Evidence of bloc voting and vote trading was also found in figure skating where Germany, USA, Canada and Italy are more likely to be negatively biased towards Russia, Ukraine, France and Poland, and vice versa [@zitzewitz_nationalism_2006]. Bloc voting in figure skating is nothing new, however. Seltzer and Glass [-@seltzer_international_1991], for example, documented consistent bloc voting along cold-war lines in addition to nationalistic biases in the Winter Olympic games held from 1968 till 1988. 

Vote trading in the 2002 Olympics led to a revamp of the scoring system for figure skating after a French judge admitted to being pressured to vote in favour of the Russian pair over the Canadian pair in the pairs’ competition final. This effectively handed the Russian pair the gold medal. Allegedly this was part of a deal with the Russian team, where they would reciprocate in a later competition in favour of the French. This scandal was examined quantitatively by Lock and Lock [-@lock_statistical_2003] using a bootstrap technique to look for inconsistencies in the scoring. Looking at the correlation between judges’ rank (of the athlete) and the final actual rank (a high correlation indicating an accurate judge), they isolated one inconsistent judge, but it was not the French one. The French judge had the best correlation of all the judges in that event; in other words, she was the most spot-on in her scoring, and no evidence of wrongdoing was found.


## Theorizing nationalistic biases in ski jumping

Our reading of the empirical literature on nationalistic and other evaluative biases concludes that there is evidence for such biases in a variety of sports. Given its existence, what are the root causes of such bias and how do they emerge? Theoretically, we can concieve of bias resulting from at least three different mechanisms. We denote these three mechanisms the social psychological mechanism, the cultural legitimacy mechanism and the differential professionalisation mechanism, and discuss each of them in turn below.

### The social psychological mechanism: Implicit or explicit nationalistic bias

The first social psychological mechanism is the simple folk psychology theory of  judges' nationalistic impulses at the subconscious or even conscious level. They prefer contestants from their own country to win, and give higher scores to those athletes.  This crude form of nationalistic bias is similar to what has been denoted taste-based discrimination, which refers to individuals’ preferences for certain categories of people and is often used to explain discrimination against women or ethnic minorities in the labour market [@becker_economics_1957]. 

Applied to ski jumping, the mechanism refers to judges’ conscious nationalistic impulses that bias their evaluations in favour of contestants from their own country, and against competitors from other countries. A subtler form of this mechanism leads to subconscious bias for jumpers from one’s own country, where own preferences or social expectations lead judges to biased evaluations [@bassettjr_rating_2005, @campbell_nonparametric_1996]. Importantly, this theoretical mechanism does not by itself predict variation in the magnitude of biases across countries. It can be combined with other theoretical ideas to arrive at predictions about any such variation.

### Theory of evaluation work, as applied to nationalistic biases in ski jumping

The second way of theorizing bias is to consider the role of judges and their efforts as evaluation work. Evaluative work and the justification for evaluations as a sociological study has been profoundly influences by the works of Boltanski \& Thevenon [-@boltanski_justification_1991]. A central tenet in their sociology of evaluations is the room for evaluation. 

The room for evaluation decides what is relevant and good in a field. The evaluative room may be wide, and allow for many different evaluative statements, or narrow, and restrict evaluative statements. The main point is that the evaluative room allows for criticisms by field actors that in turn may affect the structure of the room for evaluation. Criticisms within the room for evaluation are recognized as forces of change in organizations and society at large. Actors cannot expect to have any criticism heard, and it must be recognized by multiple actors before it is heard. If enough actors repeat and (re)formulate  a criticism, it will potentially lead to change and a new room for evaluation.

Applied to ski jumping as a field, judges' practices for scoring represents the room for evaluation. Within this room, there are likely coexisting practices that may be correlated with judges' nationalities, giving rise to national variations in judge scores. Some countries, for example, Norway and Finland, enjoy long ski jumping traditions, whereas neighbouring Sweden, an otherwise similar country, does not. Most likely, their long tradition for ski jumping imply that judges from Norway and Finland to a larger degree than Swedish judges will define the room for evalution. This became salient when Jan Boklöv, a Swede, pioneered the V-style in ski jumping. His style was not comme-il-faut among judges and competitors in ski jumping at the time, and thus heavily penalized by judges. Eventually he won competitions, due to the technical advantages of the V-style, and other actors started to mimic the style [@muller_performance_2008]. These changes then led to a change in the room for evaluations, where V-style was accepted and it is currently completely dominant in the field [@pfister_sportification_2007].

Mere national variation in judge scoring practices does not yield nationalistic biases in individual scores. However, when we also consider the fact that competitors are trained and socialized in their respective national ski jumping associations and competitions, this implies that young competitors share the more experienced judges' evaluative standards, which in turn leads to nationalistic biases in judge scoring.


### Professionalisation of sports and the evolution of evaluation

The third source of national variation in ski jumping evaluations is related to the process of professionalisation in sports. An essential ingredient in evaluation are standards. In sports, standards are continuously evolving. The continued professionalisation of sports would suggest a higher degree of standardization and a narrowing of the room for evaluations. Several aspects of contemporary ski jumping suggest that professionalisation will limit the magnitude of nationalistic biases. 

First, FIS licences judges to qualify for taking on international, high-level judging assignments. professionalisation of ski jumping entails stricter quality control of judge performances and training. Currently FIS requires national skiing associations to hold at least one national-level judge seminar every year to contribute to educating new judges, and all judges are required to participate in such seminars at least once every two years [cf. @internationalskifederation_fis_2019].

Second, there is also a system in place for auditing judges. Chapter 10 of the FIS Rules documents explains that judges are subject to an evaluation by a FIS Sub-committee working together with a data team, and that their work may result in allotting individual judges with "points" that indicate non-fair scoring practices. If judges accumulate many points, they may not be nominated to higher-level competitions or wholly excluded from judging. Such sanctioned judges may re-qualify for judging assignments after scoring performances from television broadcasts. 

Third, the competition rules also limit the influence of such biases by removing the best and worst of the five scores from the total score. This certainly limits the magnitude of any bias, but as previous research have found significant biases [@zitzewitz_nationalism_2006], it does not seem to root it completely out.

The relevance of professionalism for the *national variation* in biases emerges when we combine the idea of evaluative work with the likely different levels of professionalism among the national associations that are responsible for judge training. In countries where ski jumping is a relatively important sport, such as Finland and Norway, the bias should be less due to an assumed stronger professionalisation.

Summing up, it seems meaningful to reexamine the existence of nationalistic biases, study how these biases vary across the countries from which evaluators are drawn, and study whether nationalistic biased have decreased in magnitude over time, due to, for example, the general tendency towards increased professionalisation in sports.

In addition to the social psychological, cultural legitimacy, and differential professionalisation mechanisms discussed above, there may well be yet other mechanisms that also contribute to nationalistic biases of this kind, for example desires on part of individual judges to grow the sport's influence in their countries and that try to boost their own competitors placements. 



## Hypotheses

We propose several hypotheses on biases in international ski jumping competitions, based on the literature and theory reviewed above. On the basis of earlier findings, we propose a first hypothesis that there are nationalistic biases in ski jumping. Specifically, we expect there to be a positive bias in scores when judges score performances by athletes who are from the same nation as themselves. 

Our second hypothesis states that the gross bias is partly explained by controlling for characteristics of the jump and athlete. The empirical implication of is that the magnitude of the bias will attenuate once all unobserved factors related to the jump are controlled. 

A third hypothesis concerns variation in bias across countries. Nationalistic biases may vary across countries due to cultural, historical and professional ideosyncracies at the national level. The strength of the bias is assumed to be lower in countries without strong ski jumping cultures and higher in countries where the sport is more peripheral in the larger sports field.

Our fourth hypothesis states that nationalistic bias in ski jumping evaluations decrease over time, possibly as a result of the continued professionalisation of the sport.



# DATA AND METHODS

To test the hypotheses proposed above, we use data from the FIS World Cup competitions in ski jumping from the 2006-2007 and 2007-2008 seasons as well as from the 2015-2016 seasons. The original data for 2006-2007 and 2007-2008 seasons were downloaded from the FIS web site, coded, edited for errors, and collated into complete data set for analysis. For the season 2015-2016, we wrote automated web scraping software that identified relevant PDF files on the FIS servers, downloaded these files, and scraped them for results according to our pre-specified instructions. In accordance with norms of open social science, the software used to download and scrape the PDF files are documented in the GitHub repository associated with this article.

Both data sets include detailed information on each jump in each competition, including the five individual judge scores from the jump along with the identity and nationality of each judge in each competition. Characteristics of the jump such as speed and length are included, as well as the points allotted. The total points for the jump is the sum of the length score and the stylistic score. We also know where and when the competition was held. For the later period, additional details on wind, starting gate and point adjustments for such conditions are also available.

We exclude team events from both seasons, as team events follow a different structure than individual competitions and also because extracting data from team events are markedly more difficult than it is for individual events. Table 1 outlines the dimensionality of the two data sets.

\newpage

```{r tab1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# TABLE 1. Descriptive statistic
descheading <- c("Statistic","2005-2007","2015-2016"); numdigs = 2
thetable <- as.data.frame(rbind(
 c("","Mean / Count", "Mean / Count"),
 c("No. of competitor nations", length(unique(jumps$competitornation)), length(unique(season2016$competitorNation))),
 c("No. of unique skijumping hills", length(unique(jumps$competitionplace)),length(unique(season2016$place))),
 c("No. of unique competitors",length(unique(jumps$competitorname)), length(unique(season2016$competitorName))),
 c("No. of unique judges", length(unique(d$judge_name)), length(unique(scores16$judge_name))),
 c("No. of jumps", nrow(jumps), nrow(season2016)),
 c("No. of competitions", length(unique(jumps$competition)), length(unique(season2016$componr))),
 c("Avg. judge score", as.numeric(round(mean(as.numeric(d$judge)),numdigs)), as.numeric(round(mean(as.numeric(scores16$judge)),numdigs))),
 c("Avg. jump length", as.numeric(round(mean(jumps$length),numdigs)), as.numeric(round(mean(season2016$length),numdigs))),
 c("Avg. points", as.numeric(round(mean(jumps$points),numdigs)), as.numeric(round(mean(season2016$totalPoints),numdigs))), deparse.level=0))
colnames(thetable) <- descheading
pander(thetable, caption = "Descriptive statistics")
```

Our analysis proceeds in several steps. First, we estimate nationalistic biases using a sequence of regression models where more complexity is incorporated for each model, each model speaking to one of the first three hypoteses. We estimate the models separately for the two periods we have data for, as there may be have been change over time in the nature of nationalistic biases, the subject of our fourth hypothesis.

## Estimation of nationalistic bias using fixed effects models

Following the general approach used in most studies of nationalistic biases (in particular, @emerson_assessing_2009; @zitzewitz_nationalism_2006), we analyse systematic tendencies in scores by individual judges and by the judges’ nationality. We begin with a simple model and add complexity in subsequent steps to test our different hypotheses.

In the first, simple, model, a dummy variable $\phi(I=J)$ indicates whether the judge comes from the same country *j* as the athlete *i* or not. The model can be written as

\begin{equation}
s_{ijp} = B ∙ \phi(I=J) + \epsilon_{ijp}
\end{equation}

where $s_{ijp}$ is the score given by judge $j$, on performance $p$, by a certain athlete $i$, and $\epsilon_{ijp}$ is the error term. The $B$ coefficient in this model estimates the difference in expected score if the athlete and the judge come from the same country. Hypothesis \#1 is tested by assessing the direction and magnitude of $B$.

Such a model does not take into account other relevant differences between nations. A Norwegian judge may give higher scores to a fellow countryman’s performance due to a correspondence of their definitions of valuable stylistic elements, in accordance with national variations in evaluation practices.

Our next step is an attempt to remove such factors, by exploiting the other judges’ evaluations of the same jump in estimation of nationalistic bias. Assuming that the other four judges give an unbiased score, a more precise way to estimate the bias is to add a fixed effects-term for each jump to the model (in effect including a dummy variable for each jump). In such a model, our estimator is based on individual judges’ score deviances from the average score for each jump. If the average score represents a more objective assessment of the performance, deviations from it can be interpreted as signs of bias. Our second model is therefore

\begin{equation}
s_{ijp} = B∙\phi(I=J) + q_p + \epsilon_{ijp}
\end{equation}

where $q_p$ is the jump fixed effect. This model will not confuse differences in stylistic culture with nationalistic biases, comparing the potentially biased judge against the four other judges for each jump. The $B$ estimate recovered from this model will be compared with the corresponding parameter from model 1, and the result of this comparison can be applied to test hypothesis \#2.

A limitation of the second model is that it does not capture any inherent leniency the judges may display. If a judge consistently scores performances higher or lower than other judges, then we cannot be sure that the observed bias is not just a particular judge always scoring lower or higher than the average judge. To control for this, we add a judge fixed effect, $l_j$, which leads to an adjusted model \#2b:

\begin{equation}
s_{ijp} = B∙\phi(I=J) + q_p + l_j + \epsilon_{ijp}
\end{equation}

This model is an improvement over the previous ones, but limitations still remain. For example, there could be so-called compensating biases, where other judges on the same panel as a suspected biased judge compensate by lowering their scores when they know that one of the others will up his score. Finally, the model also assumes that bias is constant across all judges from all nations, a crucial assumption that we subsequently question in hypothesis \#3. 

## Variations across nations and time periods

In order to test our third hypothesis, we want to allow for variations in bias between groups of judges from the same nation by interacting the judge fixed-effect in model \#2 with the indicator function for judge and competitor nation correspondence. This implies the following model:

\begin{equation}
s_{ijp} = B_{j}∙(L_{j}∙\phi(I=J)) + q_p + \epsilon_{ijp}
\end{equation}

where $L_j$ is an added judge country fixed-effect. The nation-specific estimates for B provide an assessment of the average bias in scores by judges from different countries.\footnote{In principle, we could obtain individual bias estimates for each judge and then analyze these as samples of judge biases scores grouped by judges' nationalities. This would be very demanding of our data and experiments indicate that estimates would be very imprecise. We thus refrain from doing this, and only allow the bias to vary between the different judge nationalities.} We also rank countries by our selected instrument of ski jumping history, namely the historical record of Olympic ski jumping gold medals in the decades up to and including 2002 (before the seasons we study). This medal variable was constructed by scraping existing public statistics on Olympic medals in ski jumping competitions (men's Large Hill and Normal Hill only), and calculating how many medals each country has collected. The hypothesis is tested by estimating the Spearman rank correlation $\rho$ across the countries. A negative correlation indicates support for the hypothesis.

Our fourth hypothesis regards potential changes in the variation of nationalistic bias over time. In order to assess changes in the variation in nationalistic bias, we estimate a model akin to model \#2, but with an added interaction with a dummy representing the second season (with the first season as a reference group). The parameter estimate for this interaction effect, $\gamma$ provides a direct test of hypothesis with regard to changes in nationalistic bias. The model is written as 

\begin{equation}
s_{ijp} = B∙\phi(I=J) + \gamma∙I(t=2)∙\phi(I=J)+ q_p + \epsilon_{ijp}
\end{equation}

In principle, this model could include also a general tendency in judge leniency over time, but this term will be subsumed due to perfect linearity with sets of jump fixed effects (as specific jumps only take place in one season).


# RESULTS AND DISCUSSION

Our analysis of nationalistic bias proceeds in several steps. We first assess the first two hypotheses on the mere existence of nationalistic biases, and subsequently move on to the last two hypotheses on variation across nations and time periods.

## Nationalistic biases in judge scores

Table 2 presents the results from the first three estimations. Our first model yields a positive and statistically significant estimate: judges award an average of 0.136 extra points to jumpers from their home country. This is nearly one-third of the minimum increment in judge scores in ski jumping (0.5 points). Compared with within-jump variance it only amounts to a quarter of a standard deviation. This result already suggests that the magnitude of nationalistic bias in judges’ scores is limited. The estimate may be biased by, for example, cultural and historical differences between countries that lead to an over- or underappreciation of certain styles. 

\begin{landscape}
```{r tab2, echo=FALSE, results='asis'}
stargazer(model1, model2, model2b, out.header=FALSE, header=FALSE,
    single.row=TRUE,
    column.labels = c("Model 1: Naïve", "Model 2a: Within-jump", "Model 2b: Within-judge"),
    title="Results from regression models of national bias",
    covariate.labels = c("National bias"),
    dep.var.caption  = "", dep.var.labels.include = FALSE,
    model.numbers = FALSE, model.names = FALSE,
    add.lines = c(" "),
    notes.align="l",
    notes = c("In models 2a and 2b, the intercept is suppressed by the fixed effects estimation procedure."),
    notes.append=TRUE,
    df = TRUE, decimal.mark =".",
    ci=TRUE, ci.level=0.95, ci.separator = "  ",
    omit.stat=NULL,
    star.cutoffs = c(0.05,0.01,0.001)
    )
```
\end{landscape}

This was the concern of the second hypothesis, were we assumed that the bias level would decrease once we controlled for other, unobserved characteristics of the jump. Model 2a is a response to exactly this challenge, and provides a within-jump estimate of the nationalistic bias. In this model, the coefficient is estimated at 0.065, markedly lower than in the first model. It is statistically significant at the 0.1% level. The magnitude is low, but there is clearly a tendency towards nationalistic bias. In our adjusted second model \#2b, where we also include measures of individual judges' leniency, we obtain a comparable estimate of nationalistic bias (0.075, sig. at 0.1\% level).

The conclusion thus far is that there are nationalistic biases in evaluations made by judges in the FIS World Cup competitions over the last decades. These biases do not disappear once we control rigorously for unobserved characteristics of both the jump itself and the judges. The first two hypotheses are supported by the data analysis. We do not know from these results, whether the remaining nationalistic bias is due to the social psychological, cultural-historical or the differential-professionalisation mechanisms. It seems fair to allow all three to play a role.  

## Variations in bias across nations and time periods

Our third hypothesis concerned variation in nationalistic biases for judges from different countries, and whether such variation is correlated with an indicator of the historical importance of ski jumping in that country.

Our third model allowed estimating such variation, and the results are shown in Figure 2. Judges from Russia, the United States and France appear most biased. Norwegian and Slovakian judges seems to hold a negative nationalistic bias, where same-nation jumpers are punished more severely than others. Overall, the estimated biases seem fairly small and in several cases not statistically significant. It is difficult to provide a substantive interpretation of this variation in national biases, but it is nevertheless clear that the biases are relatively small in magnitude. 

The case of Slovakia is curious. This country's judges show a particularly strong negative bias. As the estimate lie well outside of the rest of the sample, it may well be reasonable to treat it as an outlier in the following analysis.

\bigskip
```{r fig2, echo=FALSE, message=FALSE, warning=FALSE, results='asis', fig.width=5, fig.align="center"}
nationbias <- broom::tidy(model3) %>% 
    mutate(country = str_sub(term, start=-3, end=-1)) %>% 
    mutate(ocountry = factor(country, levels = .$country[rev(order(.$estimate))])) %>% 
    mutate(lowci = estimate-1.96*std.error, hici=estimate+1.96*std.error) %>% 
    arrange(estimate)

figure2 <- ggplot(data = nationbias,mapping = aes(x = ocountry, y = estimate)) +
    geom_point(size=3) + 
    geom_pointrange(aes(x=country, y=estimate, ymin = lowci, ymax=hici), fatten = 1.2) +
    #color="grey") +
    #geom_segment(aes(x=country, y=estimate, xend=country, yend=0)) +
    xlab("Nation") + ylab("Strength of bias") +
    theme_minimal() +
    ggtitle("Figure 2. Nation-specific estimates of judges' bias", subtitle="Bars indicate 95% C.I.")
figure2

```
\bigskip

By itself, this piece of evidence is not enough to test hypothesis \#3, as it also suggests several specific mechanisms for the variation in biases, namely cultural-historical legacies and differential professionalisation. According to these mechanisms, the bias should be lower in countries where ski jumping has a stronger historical role in sports and where the degree of professionalisation is the highest. We are unable to directly adjudicate between these two mechanisms, as there is likely a strong positive correlation between the place of ski jumping in the national sports field and the degree of professionalisation.

To test the third hypothesis, we estimate the rank correlation of the nation-specific bias coefficient and the nation's Olympic medal harvest. 

```{r scrape-gold, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(rvest)
theurl <- here::here("second-revision/List of Olympic medalists in ski jumping - Wikipedia.html") 

#https://en.wikipedia.org/wiki/List_of_Olympic_medalists_in_ski_jumping"

webpage <- read_html(theurl)

lh_table <- webpage %>%
    html_nodes("table") %>% 
    .[[1]] %>% 
    html_table(header=T)

nh_table <- webpage %>% 
    html_nodes("table") %>% 
    .[[3]] %>% 
    html_table(header=T)

goldindex <- bind_rows(lh_table, nh_table) %>% 
    mutate(year = as.numeric(str_sub(Games,start=1,end=4))) %>%
    filter(year<2006) %>% 
    select(-Games) %>% 
    gather(key=type, value=winner, -year) %>% 
    filter(winner!="not awarded") %>% 
    mutate(country = stringi::stri_extract_last_words(winner)) %>% 
    mutate(country = case_when(country=="Union" ~ "RUS",
                               country=="States" ~ "USA",
                               country=="Japan" ~ "JPN",
                               country=="Germany" ~ "GER",
                               country=="Austria" ~ "AUT",
                               country=="Switzerland" ~ "SUI",
                               country=="Finland" ~ "FIN",
                               country=="Sweden" ~ "SWE",
                               country=="Poland" ~ "POL",
                               country=="Norway" ~ "NOR",
                               country=="Yugoslavia" ~ "SLO",
                               country=="Czechoslovakia" ~ "SVK",
                               TRUE~country)) %>% 
    group_by(country) %>% 
    summarize(medals = n()) %>% 
    arrange(medals)
cze <- goldindex %>% filter(country=="SVK") %>% pull(medals)
goldindex <- goldindex %>% add_row(country="CZE", medals=cze)

ranking <- left_join(goldindex, nationbias, by="country")

figure3 <- ggplot(filter(ranking, country!="SVK"), aes(x=medals, y=estimate, label=country)) + 
    geom_point(size=2) + 
    geom_smooth(method="lm", se=F, color="brown") +
    geom_text_repel() +
    xlab("Olympic medals") + ylab("Strength of bias") +
    ggtitle("Figure 3. Strengh of bias and Olympic medals") + 
    theme_minimal()

spearman <- cor.test( ~ medals + estimate, 
         data=ranking,
         method = "spearman",
         continuity = FALSE,
         conf.level = 0.95)

```

The Spearman $\rho$ rank correlation coefficient of nationalistic bias and Olympic medals was estimated at ```r round(spearman$estimate,3)``` which thus supports the hypothesis that the magnitude of bias is negatively related to the Olympic medal harvest for the country. If we can assume that historical medal harvest is postively related to the relative place of ski jumping in the national sports field and/or the degree of professionalisation of ski jumping, our third hypothesis must be considered supported by the data.

Figure 3 shows the scatterplot between Olympic medals and nationalistic bias estimates. An identical scatterplot that also includes the outlier Slovakia, would yield a slightly less negative relationship.

\smallskip

```{r figthree, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=5, fig.align="center"}
figure3
```

We now turn to our fourth hypothesis, which stated that nationalistic biases would decrease over time. We test this hypothesis by estimating a fourth model that includes an interaction coefficient with time period. We thus obtain two coefficients for national bias: a main effect and an interaction effect. The latter quantifies the change in bias from the 2006-2008 seasons to the 2015-2016 season.
\newpage

```{r tab3, echo=FALSE, results='asis'}
stargazer(model4, out.header=FALSE, header=FALSE,
    single.row=TRUE,
    column.labels = c("Model 4: Change over time"),
    title="Results from regression models of change over time in nationalistic bias",
    covariate.labels = c("Main bias effect","","Interaction with time"),
    dep.var.caption  = "", dep.var.labels.include = FALSE,
    model.numbers = FALSE, model.names = FALSE,
    add.lines = c(" "),
    notes.align="l",
    notes = c("The intercept is suppressed by the fixed effects estimation procedure."),
    notes.append=TRUE,
    df = TRUE, decimal.mark =".",
    ci=TRUE, ci.level=0.95, ci.separator = "  ",
    omit.stat=NULL,
    star.cutoffs = c(0.05,0.01,0.001)
    )
```

As can be seen from Table 3, the interaction effect is not measurably different from zero. It is estimated at  ```r round(bias_interact,3)``` which is a miniscule magnitude relative to the main effect of ```r round(bias_main,3)```. All in all, there does not seem to be much change in nationalistic biases over the two time periods our data set covers. The fourth hypothesis must thus be rejected. This implies that if there is an ongoing professionalisation of the sport, it has not resulted in lower nationalistic biases among judges. 


## Our results in light of the extant literature

In sum, we have learned that there are nationalistic biases in ski jumping evaluations. These biases persist when controlling for characteristics of the performance and individual judges.
The bias is less strong among nations with a historical culture of ski jumping. The bias have not declined over a decade of potentially increasing professionalisation.

What can we learn from these results in totality? At the very least, we can speculate about the origin of nationalistic biases. The simplistic social pscyhological mechanism is supported by the data, by the mere existence of biases. However, as the social psychology should not be very different across these nations, the variation among nations remains a puzzle. The absence of changes over time in bias strength is weak evidence against the idea that biases are results of "unprofessional practices" and will disappear once professionalisation increases. A possibility that remains is that, as biases are stronger among nations where ski jumping is less important in the national sports field, judges (unconsciously) from such nations give higher scores to up the chance of notable, positive results and support their sport on the national scene. 

Our bias estimates were smaller, however, than for example those reported from the Salt Lake City 2002 Winter Olympics [@zitzewitz_nationalism_2006]. The finding of generally smaller effects than those previously reported is intriguing and point to a potentially important element affecting subjective evaluation of performances: when stakes are higher, as in the prestigious Olympic games, the potential influence of biased judgments is likewise increased. The reason our results show less biases than previous research may thus be that the stakes in each of the World Cup series events are lower than the stakes in e.g. Olympic events [cf. @zitzewitz_nationalism_2006]. The mechanisms that lead to biases are somehow more often invoked or invoked in a more influential version when stakes are higher. Another potential explanation points to individual judges’ career considerations, as objective performance in regular contests can later be rewarded by participation in higher prestige events, such as the Olympics. Our results thus complement Zitzewitz’s (2006) findings by pointing out situations in which biases are more (less) likely. Future research could compare competitions that differ in status and prizes, for example competitions at the regional and the national levels, and further test this idea of bias as emergent in high-stakes competitions.

Our estimates of nationalistic biases were also small enough that they would not alter the rankings in any of the contests. A comparison with the within-jump variance indicates that the bias only amounts to around a quarter of a standard deviation (cf. Model 3 in Table 2). In other words, the variation between the judges’ scores that is not due to nationalistic bias is much larger. If this variation is considered to be random deviations from a “true” score, it is clear that competitors should worry more about chance variations in judges’ evaluations (and possible idiosyncratic opinions) than about nationalistic biases affecting the outcome of the competition. The ski jumping sport has, by implementing several safeguards, reduced the importance of nationalistic biases to a minimum.

As has been pointed out in previous research, biases in evaluations need not result from conscious actions by the judges. In related research on hiring practices in symphony orchestras [cf. @fasang_recruitment_2006], researchers have claimed that evaluators have non-conscious schemata based on external factors such as gender, which affect the perception of performances and which can be removed by blinded evaluations. In a similar manner, judge evaluations in sport contests can be affected by non-conscious biases. A judge may over- or underrate an athlete's performance based on her or his nationality, or the judge may use the behaviour of the audience as information on this performance. In such cases, ways to minimize the effects of such factors should be promoted to reduce the effects of biases on evaluations.

# CONCLUSION

In this paper, we report an analysis of data from the 2006-2008 and 2015/2016 seasons of the FIS World Cup in Nordic ski jumping.  Our overarching research question is whether there is nationalistic biases in ski jumping. In addition, we also consider whether there is still such bias when influences of the actual performance are ruled out, whether there are national variations in how strong the biases are, due for example to the different positions of ski jumping in national sports fields, and whether they change over time, possibly due to the increased professionalisation of the sport.

From our results, we confirm a major tenet of the extant literature, and document nationalistic biases in judges’ evaluations of ski jumping performances. The biases persist even when we use sophisticated fixed effects methods to remove performance-related confounders. There is also quite a bit of variation in how strong biases are between nations, and this variation is seemingly related to the historical importance of ski jumping, with nations with a stronger historical ski jumping culture displaying somewhat lower biases. The mechanism generating this trend is less understood, but may be related to differential professionalisation of ski jumping in the participating nations. However, we did not find any evidence that there is a change over the period we study in the magnitude of biases. A promising avenue for future research is to exploit the fairly recent increase in activity among female ski jumpers, which would present a less established and professionalised case and may be held to different standards than men [@hornung_darstellung_2014].

The nationalistic biases are generally small, and do not seem to pose a major threat to the validity of results from skijumping competitions. However, in league or series-type competition tournaments, the cumulative effects of nationalistic bias may still be consequential. An important takeaway from this study is that the system of regulations in ski jumping that is already in place most likely provide adequate mitigation of judges' nationalist impulses so that the objectivity and fairness of the results are not threatened. Biases in subjective evaluations of judges and referees may carry important implications for sports results, as exemplified by findings of potential effects on final rankings of athletes or on betting markets [@larsen_racial_2008, @price_racial_2010]. 

Knowledge of the sources of evaluative biases in competitive sports can potentially help us better understand biases and discriminatory practices in other fields, such as student and employee recruitment and the allocation of research grants. Our findings of nationalistic bias is evidence that, in particular when assessed together with other related findings, add to our understanding on bias-generating practices. This knowledge may aid sport organizations, as well as other types of organizations, in their control of similar biases, and produce fairer, performance evaluations in the future.


# REFERENCES

